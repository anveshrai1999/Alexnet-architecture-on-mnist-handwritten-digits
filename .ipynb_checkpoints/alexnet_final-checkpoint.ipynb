{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7843c1a8",
   "metadata": {},
   "source": [
    "<b>Importing Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb5e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all libraries\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "print('Imported all libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f52a8f",
   "metadata": {},
   "source": [
    "<b>Reading Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec78e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_digit.csv\")\n",
    "test = pd.read_csv(\"test_digit.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15e4e5",
   "metadata": {},
   "source": [
    "<b>EDA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e10e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image should show: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a random sample image file\n",
    "num = random.randint(0, len(train))\n",
    "\n",
    "label_sample, image = train.iloc[num,0], train.iloc[num,1:]\n",
    "shape = int(np.sqrt(784))\n",
    "plt.imshow(image.values.reshape(shape, shape))\n",
    "print(\"The image should show: {}\".format(label_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65128300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3222a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.label\n",
    "x_train = train.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6c2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 57, 57, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 57, 57, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 57, 57, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 29, 29, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 29, 29, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 29, 29, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 15, 15, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 15, 15, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15, 15, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 15, 15, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 15, 15, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 15, 15, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 15, 15, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 91,790,794\n",
      "Trainable params: 91,769,638\n",
      "Non-trainable params: 21,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(227, 227, 3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(10))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()\n",
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c1d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2b270f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_11_input to have 4 dimensions, but got array with shape (42000, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3f4de61e69d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAlexNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\RecSys\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RecSys\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RecSys\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_11_input to have 4 dimensions, but got array with shape (42000, 784)"
     ]
    }
   ],
   "source": [
    "AlexNet.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1121319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
