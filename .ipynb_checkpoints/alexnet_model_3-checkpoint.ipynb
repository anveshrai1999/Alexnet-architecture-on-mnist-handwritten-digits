{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ef62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers.core import Activation\n",
    "from keras import datasets\n",
    "from scipy.misc import imresize\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "y_true = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_row, img_cols = 28, 28\n",
    "input_shape = (img_row, img_cols, 1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_cols, img_row, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_cols, img_row, 1)\n",
    "\n",
    "print(\"Train set shape\", x_train.shape, 'trainlabel shape', y_train.shape)\n",
    "print('test set shape', x_test.shape, 'test labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set to validatation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "\n",
    "print('X_train shape:', x_train.shape, 'X_label shape:', y_train.shape)\n",
    "print('Val_set shape:', x_val.shape, 'val_label shape:', y_val.shape)\n",
    "print('Test_set shape:', x_test.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_val = (x_val - x_val.mean()) / x_val.std()\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13670d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 10\n",
    "\n",
    "im_row = 227\n",
    "im_col = 227\n",
    "\n",
    "def reformat(dataset):\n",
    "    dataset = np.asarray([img_to_array(array_to_img(im, scale=False).resize((im_row, im_col))) for im in dataset])\n",
    "    return dataset\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "x_train  = reformat(x_train)\n",
    "print('X_train shape:', x_train.shape, 'X_label shape:', y_train.shape)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "x_test  = reformat(x_test)\n",
    "print('test set shape:', x_test.shape, 'test label shape', y_test.shape)\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val)\n",
    "x_val  = reformat(x_val)\n",
    "print('val set shape:', x_val.shape, 'val_lavels shape:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(227,227,1), kernel_size=(11, 11), strides=(4, 4), activation='tanh'))\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='tanh'))\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='tanh'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='tanh'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='tanh'))\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000, activation='tanh'))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d344981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2524639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "from keras.optimizers import Adadelta\n",
    "opt = Adadelta(lr=0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45083d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 10\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c18afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size= 50, epochs= 20, verbose=1, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c49d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose= 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc815bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.title(\"training vs validation loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.title(\"training vs validation accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print('Confusion Matrix is given by:\\n')\n",
    "print(confusion_matrix(y_true, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5cfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1-score: {:.2f}\\n'.format(f1_score(y_true, predicted_classes,average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42a1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
